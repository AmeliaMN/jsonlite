% Generated by roxygen2 (4.0.1): do not edit by hand
\name{mongo_read}
\alias{mongo_read}
\alias{mongo_write}
\title{Read and write MongoDB collections}
\usage{
mongo_read(mongo, ns, handler, pagesize = 100, verbose = TRUE, ...)

mongo_write(x, mongo, ns, pagesize = 100, verbose = TRUE, ...)
}
\arguments{
\item{mongo}{a mongo connection from \code{\link{mongo.create}}}

\item{ns}{a mongo namespace}

\item{a}{handler function}

\item{pagesize}{number of records (dataframe rows) per iteration}

\item{verbose}{some debugging output}

\item{...}{additional parameters for \code{\link{mongo.find}} and \code{\link{fromJSON}}
(\code{mongo_read}) or for \code{\link{toJSON}} (\code{mongo_write}).}
}
\value{
The \code{mongo_write} function always returns \code{NULL}.
When no custom handler is specified, \code{mongo_read} returns a data frame of
the entire collection (all pages binded together). When a custom handler
function is specified, \code{mongo_read} always returns \code{NULL}.
}
\description{
These functions are used to import or export MongoDB collections as a
data frames, and vice versa. Because BSON uses the same structures as
JSON, the mapping between BSON data and R classes is the same as for JSON.
The functions in jsonlite have been implemented to support streaming (batch
processing) in order to be able to handle large amounts of data with limited
memory.
}
\details{
In mongo terminology, a set of records is called a \emph{collection} and it
maps to a data frame in R. A single record within the collection is called
a \emph{document}, and it maps to a row within the data frame. MongoDB uses
BSON, which extends the JSON format with some additional primitive types such
as integer, timestamp and binary. Storing data in its native types is a bit
more efficient in comparison with storing everything as text as is done for JSON.
However most of the time, the R user won't notice much difference between
BSON and JSON because the majority of most performance overhead happens
elsewhere.

The main selling point of MongoDB is that we can easily store and access big
data. MongoDB is designed to store collections that are too large to hold in
memory, or even too large to store on a single disk by setting up a cluster.
MongoDB makes it easy to query, filter, sort, aggregate or map-reduce our (big)
data collections into something smaller and more managable that lends itself
to analysis and visualization in R.

Interacting with MongoDB works very similar as JSON streaming. See the
\code{\link{stream_in}} manual page for details and examples of using
a custom \code{handler} function or IO pipe.
}
\examples{
\dontrun{
library(rmongodb)
library(nycflights13)
m <- mongo.create()
mongo_write(flights, m, "test.flights", pagesize = 1000)
mongo.count(m, "test.flights")
flights2 <- mongo_read(m, "test.flights", pagesize = 500)
all.equal(flights2, as.data.frame(flights))
mongo.remove(m, "test.flights")
}
}

